{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5 \u2014 Performance & Risk Diagnostics\n\n",
    "**Goal.** Evaluate the Opening Range strategy using the quant metrics you listed (annualized return, Sharpe, Sortino, alpha/beta, drawdowns, Calmar, consistency) plus any related ratios we may add along the way.\n\n",
    "**Plan for this notebook**\n",
    "- **5.1** Setup & data prep (load backtest, build daily return series).\n",
    "- **5.2** Compounding & annualized return (WIP).\n",
    "- **5.3** Sharpe + Sortino (WIP).\n",
    "- **5.4** Alpha/Beta vs benchmark (WIP).\n",
    "- **5.5** Drawdowns, Calmar, consistency checks (WIP).\n",
    "\nThese sections will be filled one at a time so we can review each metric block together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 \u2014 Setup & data prep (read this first)\n\n",
    "*Purpose:* pull the cleaned trade history (`reports/tables/backtest_daily_net.csv`) created in Notebook 3, compute the daily net returns, and stash a tidy DataFrame (`perf`) we will use everywhere else.\n\n",
    "*What this section does:*\n",
    "1. Makes sure notebook paths point at the project root (same helper as prior notebooks).\n",
    "2. Loads backtest results with costs already applied (so PnL is realistic).\n",
    "3. Creates helper columns: start-of-day equity, end-of-day equity, net PnL, daily return (%), plus convenience flags for \"trade\" vs \"flat\" days.\n",
    "4. Prints a tiny summary so we know the sample size before calculating ratios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n\n",
    "print('CWD:', Path.cwd())\n",
    "print('ROOT:', ROOT)\n",
    "print('Tables dir exists?', (ROOT / 'reports' / 'tables').exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 \u2014 Load backtest results & compute daily returns\n\n",
    "import pandas as pd\n",
    "import numpy as np\n\n",
    "TABLES = ROOT / 'reports' / 'tables'\n",
    "BT_CSV = TABLES / 'backtest_daily_net.csv'\n",
    "if not BT_CSV.exists():\n",
    "    raise FileNotFoundError(f'Missing {BT_CSV}. Re-run Notebook 3 to regenerate the net backtest table.')\n\n",
    "daily = pd.read_csv(BT_CSV, parse_dates=['date'])\n",
    "daily = daily.sort_values('date').reset_index(drop=True)\n\n",
    "# Use the shift column (capital before trade) to derive daily returns; avoid division by zero\n",
    "capital_start = daily['equity_shift'].replace(0, np.nan)\n",
    "daily['daily_return'] = daily['pnl_usd_net'] / capital_start\n",
    "daily['had_trade'] = daily['decision'].isin(['long', 'short'])\n",
    "daily['year'] = daily['date'].dt.year\n",
    "daily['month'] = daily['date'].dt.month\n\n",
    "perf = daily[['date','decision','had_trade','pnl_usd_net','daily_return','equity_shift','equity_net','drawdown_net']].copy()\n",
    "perf.rename(columns={'equity_shift': 'equity_start', 'equity_net': 'equity_end', 'drawdown_net': 'drawdown'}, inplace=True)\n",
    "perf.set_index('date', inplace=True)\n\n",
    "summary = {\n",
    "    'start_date': perf.index.min().date(),\n",
    "    'end_date': perf.index.max().date(),\n",
    "    'trading_days': int(perf.shape[0]),\n",
    "    'days_with_trades': int(perf['had_trade'].sum()),\n",
    "    'days_flat': int((~perf['had_trade']).sum()),\n",
    "    'ending_equity': float(perf['equity_end'].iloc[-1]),\n",
    "}\n",
    "display(pd.Series(summary, name='Backtest sample'))\n",
    "display(perf.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 \u2014 Compounding & annualized return\n\n",
    "Annualized returns indicate whether the strategy grows capital fast enough to justify risk. Two complementary looks are summarised below:\n",
    "- **Daily-compounded annualized return:** product of daily net returns rescaled to 252 trading days.\n",
    "- **Calendar CAGR:** growth rate implied by beginning and ending equity over the full calendar span.\n\n",
    "Both are compared with the >10% per-year benchmark in the metric checklist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 \u2014 Annualized return diagnostics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TRADING_DAYS = 252\n",
    "daily_returns = perf['daily_return'].dropna()\n",
    "trading_days = len(daily_returns)\n",
    "years_span = max((perf.index.max() - perf.index.min()).days / 365.25, trading_days / TRADING_DAYS)\n",
    "\n",
    "equity_start = perf['equity_start'].iloc[0]\n",
    "equity_end = perf['equity_end'].iloc[-1]\n",
    "total_return = equity_end / equity_start - 1\n",
    "ann_return = (1 + daily_returns).prod() ** (TRADING_DAYS / trading_days) - 1 if trading_days else np.nan\n",
    "cagr = (equity_end / equity_start) ** (1 / years_span) - 1 if years_span > 0 else np.nan\n",
    "\n",
    "metrics = pd.DataFrame([\n",
    "    {\"metric\": \"Total return\", \"value\": total_return, \"target\": \"Positive (>0)\", \"meets_target\": total_return > 0},\n",
    "    {\"metric\": \"Annualized return (daily compounding)\", \"value\": ann_return, \"target\": \">=10%\", \"meets_target\": ann_return >= 0.10},\n",
    "    {\"metric\": \"CAGR (calendar years)\", \"value\": cagr, \"target\": \">=10%\", \"meets_target\": cagr >= 0.10},\n",
    "])\n",
    "display(metrics.style.format({\"value\": \"{:.2%}\"}))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "ax.plot(perf.index, perf['equity_end'], color='tab:blue', label='Net equity')\n",
    "ax.set_title('Net equity curve (cost-adjusted)')\n",
    "ax.set_ylabel('USD')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "\n#### 5.2 \u2014 Conclusion\n\nNet equity compounds from **$100k \u2192 ~$391k** (\u2248**+291% total return**), so both daily-compounded annualized return (~43%) and calendar CAGR (~41%) easily clear the >10% hurdle. The equity curve still shows multi-month giveback phases, so subsequent sections must confirm that the risk-adjusted profile (Sharpe/Sortino, drawdowns) matches this growth pace.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "\n### 5.3 \u2014 Sharpe & Sortino ratios\n\nRisk-adjusted ratios show how efficiently the strategy converts volatility into returns. Two complementary statistics are used:\n\n- **Sharpe ratio** measures excess return per unit of total volatility.  \\\n  $\\displaystyle S = \\frac{\\sqrt{252} \\, \\mathbb{E}[R_d - r_f]}{\\sigma(R_d - r_f)}$ where $R_d$ is the daily return and $r_f$ is the daily risk-free rate.\n- **Sortino ratio** only penalizes downside volatility relative to a target (here 0% daily).  \\\n  $\\displaystyle So = \\frac{\\sqrt{252} \\, \\mathbb{E}[R_d - T]}{\\sigma(\\min(0, R_d - T))}$ with $T$ = target return.\n\nExample: if a strategy averages +0.10% per day with 1.0% standard deviation, then $S \u2248 1.6$; if the downside deviation is 0.4%, then $So \u2248 2.5$. Higher ratios mean the equity curve grows steeply relative to its swings. Targets from the metric checklist: **Sharpe \u2265 1.0** (\u22651.5 preferred) and **Sortino \u2265 1.5**.\n\nHere, $r_f$ is set to 3% annualised (approximate short-term US T-bill yield); feel free to adjust if your funding cost differs.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "\n# 5.3 \u2014 Sharpe & Sortino diagnostics\n\nRF_ANNUAL = 0.03  # adjust if you assume a different financing rate\nTARGET_DAILY = 0.0\n\ndaily_returns = perf['daily_return'].dropna()\nrf_daily = RF_ANNUAL / TRADING_DAYS\nexcess = daily_returns - rf_daily\nvol = excess.std(ddof=0)\nsharpe = np.sqrt(TRADING_DAYS) * excess.mean() / vol if vol > 0 else np.nan\n\ndownside = np.minimum(0, daily_returns - TARGET_DAILY)\ndownside_std = np.sqrt((downside ** 2).mean())\nsortino = (np.sqrt(TRADING_DAYS) * (daily_returns.mean() - TARGET_DAILY) / downside_std\n           if downside_std > 0 else np.nan)\n\nwin_rate = (daily_returns > TARGET_DAILY).mean()\navg_gain = daily_returns[daily_returns > TARGET_DAILY].mean()\navg_loss = daily_returns[daily_returns <= TARGET_DAILY].mean()\n\nmetrics = pd.DataFrame([\n    {\"metric\": \"Sharpe ratio\", \"value\": sharpe, \"target\": \">= 1.0 (>=1.5 ideal)\", \"meets_target\": sharpe >= 1.0},\n    {\"metric\": \"Sortino ratio\", \"value\": sortino, \"target\": \">= 1.5\", \"meets_target\": sortino >= 1.5},\n    {\"metric\": \"Daily win rate\", \"value\": win_rate, \"target\": \"Context\", \"meets_target\": np.nan},\n    {\"metric\": \"Avg gain (when >0)\", \"value\": avg_gain, \"target\": \"Context\", \"meets_target\": np.nan},\n    {\"metric\": \"Avg loss (when <=0)\", \"value\": avg_loss, \"target\": \"Context\", \"meets_target\": np.nan},\n])\n\ndef _format_value(v):\n    if pd.isna(v):\n        return '\u2014'\n    if abs(v) < 1:\n        return f\"{v:.2%}\"\n    return f\"{v:.2f}\"\n\nmetrics['value_display'] = metrics['value'].apply(_format_value)\ndisplay(metrics[['metric','value_display','target','meets_target']])\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\naxes[0].hist(daily_returns, bins=40, color='tab:blue', alpha=0.8)\naxes[0].axvline(TARGET_DAILY, color='black', linestyle='--', linewidth=1)\naxes[0].set_title('Distribution of daily returns (net)')\naxes[0].set_xlabel('Daily return')\naxes[0].set_ylabel('Frequency')\n\nrolling_sharpe = (daily_returns - rf_daily).rolling(window=63, min_periods=20).apply(\n    lambda x: np.sqrt(TRADING_DAYS) * x.mean() / x.std(ddof=0) if x.std(ddof=0) > 0 else np.nan, raw=False\n)\naxes[1].plot(rolling_sharpe.index, rolling_sharpe, color='tab:orange')\naxes[1].axhline(1.0, color='grey', linestyle='--', linewidth=1, label='Sharpe = 1')\naxes[1].axhline(1.5, color='grey', linestyle=':', linewidth=1, label='Sharpe = 1.5')\naxes[1].set_title('63-day rolling Sharpe (cost-adjusted)')\naxes[1].set_ylabel('Ratio')\naxes[1].grid(True, alpha=0.3)\naxes[1].legend(loc='upper left')\n\nplt.tight_layout()\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "\n#### 5.3 \u2014 Conclusion\n\nSharpe \u2248 **1.7** and Sortino \u2248 **3.5**, so the strategy comfortably exceeds the \u22651 / \u22651.5 thresholds despite posting gains on only ~30% of sessions. Large winners relative to modest average losses drive the high ratios, but the win-rate profile confirms the need for strict discipline during losing streaks. Rolling Sharpe mostly stays above 1 after 2020, suggesting the risk-adjusted edge persists across market regimes sampled here.\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}